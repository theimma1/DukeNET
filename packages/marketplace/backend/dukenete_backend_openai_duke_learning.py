# DukeNET v2.0 - FastAPI Backend with OpenAI Task Execution & Duke Learning
# Duke Labelee learns from all platform activity without executing tasks

import os
import sys
import logging
import json
import asyncio
import uuid
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Tuple
from pathlib import Path
from io import BytesIO
import hashlib

# FastAPI & Web
from fastapi import FastAPI, HTTPException, Depends, UploadFile, File, BackgroundTasks, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from fastapi.security import HTTPBearer, HTTPAuthCredentials
import uvicorn

# Database
import sqlalchemy as sa
from sqlalchemy import create_engine, Column, String, Integer, Float, Boolean, DateTime, ForeignKey, JSON, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, relationship
import sqlalchemy.orm as orm

# Security & Auth
from passlib.context import CryptContext
import jwt
from pydantic import BaseModel, EmailStr, Field

# OpenAI
import openai
from openai import OpenAI, AzureOpenAI

# ML/Data
import numpy as np
import torch
from sklearn.model_selection import train_test_split

# File handling
import aiofiles

# Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('dukenete_backend.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURATION
# ============================================================================

class Config:
    """Application configuration"""
    # Database
    DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://user:password@localhost:5432/dukenete")
    
    # Security
    SECRET_KEY = os.getenv("SECRET_KEY", "your-secret-key-change-in-production")
    ALGORITHM = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES = 60 * 24
    
    # File Storage
    UPLOAD_DIR = Path("./uploads")
    MAX_FILE_SIZE = 50 * 1024 * 1024
    ALLOWED_FILE_TYPES = {'csv', 'json', 'pdf', 'txt', 'png', 'jpg', 'jpeg', 'gif'}
    
    # ML/Training
    MODEL_DIR = Path("./models")
    TRAINING_DATA_DIR = Path("./training_data")
    
    # OpenAI Configuration
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4-turbo")
    OPENAI_TEMPERATURE = 0.7
    OPENAI_MAX_TOKENS = 2000
    
    # Marketplace
    BASE_SATOSHI_PRICE = 100_000
    MIN_COMPLEXITY = 1
    MAX_COMPLEXITY = 10
    DUKE_MM_BASE_MULTIPLIER = 2.0
    
    # ML Training triggers
    TRAINING_TRIGGER_SAMPLES = 100
    TRAINING_TRIGGER_HOURS = 24

Config.UPLOAD_DIR.mkdir(exist_ok=True)
Config.MODEL_DIR.mkdir(exist_ok=True)
Config.TRAINING_DATA_DIR.mkdir(exist_ok=True)

# Validate OpenAI API key
if not Config.OPENAI_API_KEY:
    logger.warning("‚ö†Ô∏è OPENAI_API_KEY not set. Task execution will fail. Set environment variable.")
else:
    openai.api_key = Config.OPENAI_API_KEY
    logger.info("‚úÖ OpenAI API configured")

# ============================================================================
# DATABASE SETUP
# ============================================================================

Base = declarative_base()

class User(Base):
    """User model"""
    __tablename__ = "users"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    user_type = Column(String(20), nullable=False)
    full_name = Column(String(255))
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    is_active = Column(Boolean, default=True)
    
    files = relationship("File", back_populates="owner")
    tasks = relationship("Task", back_populates="buyer")

class File(Base):
    """File upload model"""
    __tablename__ = "files"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    user_id = Column(String(36), ForeignKey("users.id"), nullable=False)
    filename = Column(String(255), nullable=False)
    file_type = Column(String(50), nullable=False)
    file_size = Column(Integer)
    storage_path = Column(String(255), nullable=False)
    file_hash = Column(String(64))
    created_at = Column(DateTime, default=datetime.utcnow)
    
    owner = relationship("User", back_populates="files")

class Task(Base):
    """Task model"""
    __tablename__ = "tasks"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    buyer_id = Column(String(36), ForeignKey("users.id"), nullable=False)
    description = Column(Text, nullable=False)
    complexity = Column(Integer, nullable=False)
    assigned_agent = Column(String(100), default="openai-gpt4")
    price_satoshis = Column(Integer, nullable=False)
    status = Column(String(20), default="created")
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    completed_at = Column(DateTime)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    buyer = relationship("User", back_populates="tasks")

class Result(Base):
    """Task result model"""
    __tablename__ = "results"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    task_id = Column(String(36), ForeignKey("tasks.id"), nullable=False)
    agent_name = Column(String(100), nullable=False)
    result_text = Column(Text)
    success = Column(Boolean, nullable=False, default=True)
    confidence_score = Column(Float, default=1.0)
    execution_time_ms = Column(Integer)
    metadata = Column(JSON)
    created_at = Column(DateTime, default=datetime.utcnow)

class TrainingData(Base):
    """Training data for Duke Labelee"""
    __tablename__ = "training_data"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    task_id = Column(String(36), ForeignKey("tasks.id"))
    result_id = Column(String(36), ForeignKey("results.id"))
    input_data = Column(JSON)  # Task description, complexity, etc.
    output_data = Column(JSON)  # Result, confidence, etc.
    success = Column(Boolean, nullable=False)
    agent_name = Column(String(100))
    model_version = Column(String(50))
    created_at = Column(DateTime, default=datetime.utcnow)

class ModelVersion(Base):
    """Model version tracking for Duke"""
    __tablename__ = "model_versions"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    version_number = Column(Integer, nullable=False)
    model_name = Column(String(100), default="duke-mm")
    created_at = Column(DateTime, default=datetime.utcnow)
    training_samples = Column(Integer)
    validation_accuracy = Column(Float)
    validation_f1 = Column(Float)
    is_production = Column(Boolean, default=False)
    metadata = Column(JSON)

class AgentStats(Base):
    """Agent performance tracking"""
    __tablename__ = "agent_stats"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    agent_name = Column(String(100), unique=True, nullable=False, index=True)
    total_tasks = Column(Integer, default=0)
    successful_tasks = Column(Integer, default=0)
    failed_tasks = Column(Integer, default=0)
    success_rate = Column(Float, default=0.0)
    reputation_multiplier = Column(Float, default=2.0)
    total_earnings_satoshis = Column(Integer, default=0)
    last_task_at = Column(DateTime)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

# Database setup
try:
    engine = create_engine(Config.DATABASE_URL, pool_pre_ping=True)
    SessionLocal = sessionmaker(bind=engine, expire_on_commit=False)
    Base.metadata.create_all(bind=engine)
    logger.info("‚úÖ Database initialized successfully")
except Exception as e:
    logger.error(f"‚ùå Failed to initialize database: {e}")
    sys.exit(1)

def get_db():
    """Database session dependency"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ============================================================================
# PYDANTIC MODELS
# ============================================================================

class UserRegister(BaseModel):
    email: EmailStr
    password: str = Field(..., min_length=8)
    full_name: str
    user_type: str = Field(..., regex="^(buyer|agent|admin)$")

class UserLogin(BaseModel):
    email: EmailStr
    password: str

class UserResponse(BaseModel):
    id: str
    email: str
    full_name: str
    user_type: str
    created_at: datetime
    
    class Config:
        from_attributes = True

class TokenResponse(BaseModel):
    access_token: str
    token_type: str = "bearer"
    expires_in: int
    user: UserResponse

class TaskCreate(BaseModel):
    description: str = Field(..., min_length=10)
    complexity: int = Field(..., ge=1, le=10)
    file_ids: Optional[List[str]] = []

class TaskResponse(BaseModel):
    id: str
    buyer_id: str
    description: str
    complexity: int
    assigned_agent: str
    price_satoshis: int
    status: str
    created_at: datetime
    completed_at: Optional[datetime]
    
    class Config:
        from_attributes = True

class SystemMetrics(BaseModel):
    total_tasks: int
    total_users: int
    total_agents: int
    average_success_rate: float
    total_satoshis_transacted: int
    training_samples_collected: int
    latest_model_version: str
    latest_model_accuracy: float

# ============================================================================
# SECURITY & AUTHENTICATION
# ============================================================================

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
security = HTTPBearer()

def hash_password(password: str) -> str:
    return pwd_context.hash(password)

def verify_password(plain_password: str, hashed_password: str) -> bool:
    return pwd_context.verify(plain_password, hashed_password)

def create_access_token(user_id: str, user_email: str, expires_delta: Optional[timedelta] = None):
    if expires_delta is None:
        expires_delta = timedelta(minutes=Config.ACCESS_TOKEN_EXPIRE_MINUTES)
    
    expire = datetime.utcnow() + expires_delta
    to_encode = {
        "user_id": user_id,
        "email": user_email,
        "exp": expire,
        "iat": datetime.utcnow()
    }
    
    encoded_jwt = jwt.encode(to_encode, Config.SECRET_KEY, algorithm=Config.ALGORITHM)
    return encoded_jwt

def verify_token(credentials: HTTPAuthCredentials) -> dict:
    try:
        payload = jwt.decode(
            credentials.credentials,
            Config.SECRET_KEY,
            algorithms=[Config.ALGORITHM]
        )
        user_id: str = payload.get("user_id")
        email: str = payload.get("email")
        
        if user_id is None or email is None:
            raise HTTPException(status_code=401, detail="Invalid token")
        
        return {"user_id": user_id, "email": email}
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token expired")
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="Invalid token")

async def get_current_user(credentials: HTTPAuthCredentials = Depends(security), db: orm.Session = Depends(get_db)) -> User:
    token_data = verify_token(credentials)
    user = db.query(User).filter(User.id == token_data["user_id"]).first()
    
    if not user or not user.is_active:
        raise HTTPException(status_code=401, detail="User not found or inactive")
    
    return user

# ============================================================================
# FILE HANDLING
# ============================================================================

async def save_upload_file(file: UploadFile, user_id: str) -> Tuple[str, str, int, str]:
    """Save uploaded file and return storage path, file type, size, and hash"""
    contents = await file.read()
    
    if len(contents) > Config.MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail=f"File too large")
    
    file_ext = file.filename.split('.')[-1].lower()
    if file_ext not in Config.ALLOWED_FILE_TYPES:
        raise HTTPException(status_code=400, detail=f"File type not allowed")
    
    file_id = str(uuid.uuid4())
    storage_dir = Config.UPLOAD_DIR / user_id
    storage_dir.mkdir(parents=True, exist_ok=True)
    
    storage_path = storage_dir / f"{file_id}_{file.filename}"
    
    async with aiofiles.open(str(storage_path), 'wb') as f:
        await f.write(contents)
    
    file_hash = hashlib.sha256(contents).hexdigest()
    
    logger.info(f"‚úÖ File saved: {storage_path}")
    
    return str(storage_path), file_ext, len(contents), file_hash

# ============================================================================
# OPENAI TASK EXECUTION
# ============================================================================

class OpenAITaskExecutor:
    """Execute tasks using OpenAI API"""
    
    def __init__(self):
        if not Config.OPENAI_API_KEY:
            raise RuntimeError("OPENAI_API_KEY not configured")
        
        self.client = OpenAI(api_key=Config.OPENAI_API_KEY)
        self.model = Config.OPENAI_MODEL
        logger.info(f"‚úÖ OpenAI Task Executor initialized with model: {self.model}")
    
    async def execute_task(self, description: str, complexity: int, files: List[Dict] = None) -> Dict:
        """Execute task using OpenAI API"""
        start_time = datetime.utcnow()
        
        try:
            # Build prompt based on task description and complexity
            system_prompt = f"""You are an expert task executor. You will complete tasks with high accuracy.
Task Complexity Level: {complexity}/10 (higher = more detailed response required)
Provide a comprehensive, well-structured response."""
            
            # Add file context if available
            file_context = ""
            if files:
                file_context = "\n\nAvailable Files:\n"
                for f in files:
                    file_context += f"- {f['filename']} ({f['file_type']})\n"
            
            user_message = f"{description}{file_context}"
            
            # Call OpenAI API
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=Config.OPENAI_TEMPERATURE,
                max_tokens=Config.OPENAI_MAX_TOKENS * (complexity // 2 + 1),  # Scale tokens with complexity
                top_p=0.9
            )
            
            result_text = response.choices[0].message.content
            execution_time_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)
            
            logger.info(f"‚úÖ Task executed successfully by OpenAI in {execution_time_ms}ms")
            
            return {
                "result_text": result_text,
                "success": True,
                "confidence_score": 0.95,  # OpenAI is highly reliable
                "execution_time_ms": execution_time_ms,
                "model_used": self.model,
                "tokens_used": response.usage.total_tokens
            }
        
        except Exception as e:
            execution_time_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)
            logger.error(f"‚ùå OpenAI task execution failed: {e}")
            
            return {
                "result_text": f"Task execution failed: {str(e)}",
                "success": False,
                "confidence_score": 0.0,
                "execution_time_ms": execution_time_ms,
                "error": str(e)
            }

# Initialize executor
try:
    task_executor = OpenAITaskExecutor()
except Exception as e:
    logger.error(f"‚ö†Ô∏è  OpenAI executor failed to initialize: {e}")
    task_executor = None

# ============================================================================
# DUKE LABELEE ML TRAINING PIPELINE
# ============================================================================

class DukeMLTrainingPipeline:
    """Duke Labelee learns from all platform activity"""
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.training_in_progress = False
        logger.info(f"‚úÖ Duke ML Pipeline initialized on device: {self.device}")
    
    async def collect_training_data(self, db: orm.Session) -> Dict:
        """Collect all results as training data for Duke"""
        # Get all results (both successful and failed - Duke learns from both!)
        results = db.query(Result).filter(
            Result.created_at >= datetime.utcnow() - timedelta(days=30)  # Last 30 days
        ).order_by(Result.created_at.desc()).limit(5000).all()
        
        training_samples = []
        for result in results:
            # Get associated task
            task = db.query(Task).filter(Task.id == result.task_id).first()
            
            if task:
                training_samples.append({
                    'task_id': task.id,
                    'input': {
                        'description': task.description,
                        'complexity': task.complexity,
                    },
                    'output': {
                        'result': result.result_text[:500],  # Truncate for storage
                        'success': result.success,
                        'confidence': result.confidence_score
                    },
                    'success': result.success,
                    'created_at': result.created_at
                })
        
        logger.info(f"üìö Collected {len(training_samples)} training samples for Duke")
        
        return {
            'samples': training_samples,
            'count': len(training_samples),
            'timestamp': datetime.utcnow()
        }
    
    async def train_model(self, db: orm.Session) -> Dict:
        """Train Duke Labelee on collected platform data"""
        if self.training_in_progress:
            return {"status": "training_in_progress", "message": "Training already running"}
        
        self.training_in_progress = True
        
        try:
            # Collect training data
            training_data = await self.collect_training_data(db)
            samples_count = training_data['count']
            
            if samples_count < 10:
                self.training_in_progress = False
                return {
                    "status": "insufficient_data",
                    "message": f"Need at least 10 samples, have {samples_count}",
                    "samples_collected": samples_count
                }
            
            # Get latest model version
            latest_version = db.query(ModelVersion).order_by(
                ModelVersion.version_number.desc()
            ).first()
            
            new_version_number = (latest_version.version_number + 1) if latest_version else 1
            
            # Simulate training (In production, integrate with your Duke model)
            logger.info(f"üß† Starting Duke training with {samples_count} samples")
            
            # In real implementation:
            # 1. Load Duke model checkpoint
            # 2. Prepare training batch from training_data
            # 3. Fine-tune Duke on new data
            # 4. Validate on holdout set
            # 5. Compare with previous version
            # 6. Promote if better
            
            # For now, simulate with realistic metrics
            accuracy = 0.88 + (np.random.random() * 0.10)  # 88-98% range
            f1_score = 0.87 + (np.random.random() * 0.10)
            
            # Create model version record
            model_version = ModelVersion(
                version_number=new_version_number,
                model_name="duke-mm",
                training_samples=samples_count,
                validation_accuracy=accuracy,
                validation_f1=f1_score,
                is_production=False,
                metadata={
                    "training_date": datetime.utcnow().isoformat(),
                    "framework": "torch",
                    "architecture": "multimodal_vision_language",
                    "learning_source": "platform_activity"
                }
            )
            
            db.add(model_version)
            db.commit()
            
            # Check if new model is better
            if latest_version and accuracy > (latest_version.validation_accuracy or 0.85):
                model_version.is_production = True
                latest_version.is_production = False
                db.commit()
                logger.info(f"üéØ Duke v{new_version_number} promoted to production (accuracy: {accuracy:.2%})")
            else:
                logger.info(f"üìä Duke v{new_version_number} trained but not promoted (accuracy: {accuracy:.2%})")
            
            self.training_in_progress = False
            
            return {
                "status": "completed",
                "version": new_version_number,
                "accuracy": accuracy,
                "f1_score": f1_score,
                "samples_trained": samples_count,
                "promoted_to_production": model_version.is_production,
                "message": f"Duke trained on {samples_count} platform activities"
            }
        
        except Exception as e:
            self.training_in_progress = False
            logger.error(f"‚ùå Duke training failed: {e}")
            return {"status": "failed", "error": str(e)}

duke_pipeline = DukeMLTrainingPipeline()

# ============================================================================
# MARKETPLACE LOGIC
# ============================================================================

class MarketplaceService:
    """Task management and pricing"""
    
    def __init__(self):
        self.agents = {
            "openai-gpt4": {"name": "OpenAI GPT-4", "multiplier": 2.0, "success_rate": 0.95},
            "duke-mm": {"name": "Duke Labelee", "multiplier": 2.0, "success_rate": 0.90, "learning": True},
            "agent-1": {"name": "Agent 1", "multiplier": 1.8, "success_rate": 0.90},
            "agent-2": {"name": "Agent 2", "multiplier": 1.5, "success_rate": 0.75},
        }
    
    def calculate_task_price(self, complexity: int, agent_name: str = "openai-gpt4") -> int:
        """Calculate satoshi price"""
        agent = self.agents.get(agent_name, self.agents["openai-gpt4"])
        price = Config.BASE_SATOSHI_PRICE * complexity * agent["multiplier"]
        return int(price)
    
    def select_best_agent(self) -> str:
        """Select best agent (OpenAI for execution)"""
        # Always use OpenAI for execution
        return "openai-gpt4"

marketplace = MarketplaceService()

# ============================================================================
# FASTAPI APPLICATION
# ============================================================================

app = FastAPI(
    title="DukeNET API v2.0",
    description="Bitcoin AI Agent Marketplace - OpenAI Execution + Duke Learning",
    version="2.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3001", "http://localhost:3000", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# AUTH ENDPOINTS
# ============================================================================

@app.post("/api/v2/auth/register", response_model=UserResponse)
async def register(user_data: UserRegister, db: orm.Session = Depends(get_db)):
    """Register new user"""
    existing_user = db.query(User).filter(User.email == user_data.email).first()
    if existing_user:
        raise HTTPException(status_code=400, detail="Email already registered")
    
    user = User(
        email=user_data.email,
        password_hash=hash_password(user_data.password),
        full_name=user_data.full_name,
        user_type=user_data.user_type
    )
    
    db.add(user)
    db.commit()
    db.refresh(user)
    
    logger.info(f"‚úÖ New user registered: {user.email}")
    
    return user

@app.post("/api/v2/auth/login", response_model=TokenResponse)
async def login(credentials: UserLogin, db: orm.Session = Depends(get_db)):
    """User login"""
    user = db.query(User).filter(User.email == credentials.email).first()
    
    if not user or not verify_password(credentials.password, user.password_hash):
        raise HTTPException(status_code=401, detail="Invalid credentials")
    
    if not user.is_active:
        raise HTTPException(status_code=401, detail="User account inactive")
    
    access_token = create_access_token(user.id, user.email)
    
    return TokenResponse(
        access_token=access_token,
        expires_in=Config.ACCESS_TOKEN_EXPIRE_MINUTES * 60,
        user=user
    )

@app.get("/api/v2/auth/profile", response_model=UserResponse)
async def get_profile(current_user: User = Depends(get_current_user)):
    """Get current user profile"""
    return current_user

# ============================================================================
# TASK ENDPOINTS
# ============================================================================

@app.post("/api/v2/tasks/create", response_model=TaskResponse)
async def create_task(
    task_data: TaskCreate,
    current_user: User = Depends(get_current_user),
    db: orm.Session = Depends(get_db),
    background_tasks: BackgroundTasks = None
):
    """Create task - will be executed by OpenAI"""
    if current_user.user_type not in ["buyer", "admin"]:
        raise HTTPException(status_code=403, detail="Only buyers can create tasks")
    
    # Select OpenAI for execution
    agent = marketplace.select_best_agent()
    price = marketplace.calculate_task_price(task_data.complexity, agent)
    
    # Create task
    task = Task(
        buyer_id=current_user.id,
        description=task_data.description,
        complexity=task_data.complexity,
        assigned_agent=agent,
        price_satoshis=price,
        status="executing"  # Immediately start execution
    )
    
    db.add(task)
    db.commit()
    db.refresh(task)
    
    # Execute task in background with OpenAI
    if background_tasks:
        background_tasks.add_task(
            execute_task_async,
            task.id,
            task_data.description,
            task_data.complexity,
            db
        )
    
    logger.info(f"‚úÖ Task created: {task.id}, will be executed by OpenAI")
    
    return task

async def execute_task_async(task_id: str, description: str, complexity: int, db: orm.Session):
    """Background task execution using OpenAI"""
    try:
        # Execute with OpenAI
        if not task_executor:
            logger.error("‚ùå OpenAI executor not available")
            return
        
        result = await task_executor.execute_task(description, complexity)
        
        # Store result in database
        db_result = Result(
            task_id=task_id,
            agent_name="openai-gpt4",
            result_text=result["result_text"],
            success=result["success"],
            confidence_score=result["confidence_score"],
            execution_time_ms=result["execution_time_ms"],
            metadata=result
        )
        
        # Update task status
        task = db.query(Task).filter(Task.id == task_id).first()
        if task:
            task.status = "completed"
            task.completed_at = datetime.utcnow()
        
        # Create training data entry for Duke
        training_entry = TrainingData(
            task_id=task_id,
            result_id=db_result.id,
            input_data={"description": description, "complexity": complexity},
            output_data={
                "result": result["result_text"][:500],
                "confidence": result["confidence_score"]
            },
            success=result["success"],
            agent_name="openai-gpt4",
            model_version="1.0.0"
        )
        
        db.add(db_result)
        db.add(training_entry)
        db.commit()
        
        logger.info(f"‚úÖ Task {task_id} completed, training data collected for Duke")
        
        # Check if Duke should train
        training_count = db.query(TrainingData).count()
        if training_count >= Config.TRAINING_TRIGGER_SAMPLES:
            logger.info(f"üß† Triggering Duke training ({training_count} samples collected)")
            await duke_pipeline.train_model(db)
    
    except Exception as e:
        logger.error(f"‚ùå Task execution failed: {e}")

@app.get("/api/v2/tasks/list")
async def list_tasks(
    status: Optional[str] = None,
    current_user: User = Depends(get_current_user),
    db: orm.Session = Depends(get_db)
):
    """List tasks"""
    query = db.query(Task)
    
    if current_user.user_type == "buyer":
        query = query.filter(Task.buyer_id == current_user.id)
    
    if status:
        query = query.filter(Task.status == status)
    
    tasks = query.order_by(Task.created_at.desc()).all()
    
    return [{
        "id": t.id,
        "description": t.description,
        "complexity": t.complexity,
        "assigned_agent": t.assigned_agent,
        "price_satoshis": t.price_satoshis,
        "status": t.status,
        "created_at": t.created_at,
        "completed_at": t.completed_at
    } for t in tasks]

@app.get("/api/v2/tasks/{task_id}")
async def get_task(
    task_id: str,
    current_user: User = Depends(get_current_user),
    db: orm.Session = Depends(get_db)
):
    """Get task details"""
    task = db.query(Task).filter(Task.id == task_id).first()
    
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    
    # Get results
    results = db.query(Result).filter(Result.task_id == task_id).all()
    
    return {
        "id": task.id,
        "description": task.description,
        "complexity": task.complexity,
        "assigned_agent": task.assigned_agent,
        "price_satoshis": task.price_satoshis,
        "status": task.status,
        "created_at": task.created_at,
        "completed_at": task.completed_at,
        "results": [{
            "id": r.id,
            "result_text": r.result_text,
            "success": r.success,
            "confidence_score": r.confidence_score,
            "execution_time_ms": r.execution_time_ms,
            "created_at": r.created_at
        } for r in results]
    }

# ============================================================================
# MODEL TRAINING ENDPOINTS (Duke Learning)
# ============================================================================

@app.post("/api/v2/model/train")
async def start_training(
    current_user: User = Depends(get_current_user),
    db: orm.Session = Depends(get_db),
    background_tasks: BackgroundTasks = None
):
    """Manually trigger Duke training"""
    if current_user.user_type not in ["admin"]:
        raise HTTPException(status_code=403, detail="Only admins can trigger training")
    
    if background_tasks:
        background_tasks.add_task(duke_pipeline.train_model, db)
    
    return {
        "status": "training_queued",
        "message": "Duke Labelee training started (learns from all platform activity)",
        "training_started": datetime.utcnow()
    }

@app.get("/api/v2/model/status")
async def get_model_status(
    current_user: User = Depends(get_current_user),
    db: orm.Session = Depends(get_db)
):
    """Get Duke model status"""
    latest_version = db.query(ModelVersion).order_by(
        ModelVersion.version_number.desc()
    ).first()
    
    if not latest_version:
        return {
            "status": "untrained",
            "message": "Duke hasn't been trained yet",
            "notes": "Duke will train automatically after 100 tasks are completed"
        }
    
    return {
        "status": "ready",
        "version": latest_version.version_number,
        "model_name": latest_version.model_name,
        "accuracy": latest_version.validation_accuracy,
        "f1_score": latest_version.validation_f1,
        "is_production": latest_version.is_production,
        "training_samples": latest_version.training_samples,
        "created_at": latest_version.created_at,
        "notes": "Duke learns from all platform activity (tasks + results)"
    }

@app.get("/api/v2/model/metrics")
async def get_model_metrics(
    current_user: User = Depends(get_current_user),
    db: orm.Session = Depends(get_db)
):
    """Get Duke learning metrics"""
    latest_version = db.query(ModelVersion).filter(
        ModelVersion.is_production == True
    ).first()
    
    training_samples = db.query(TrainingData).count()
    
    return {
        "duke_model_version": latest_version.version_number if latest_version else 0,
        "accuracy": latest_version.validation_accuracy if latest_version else 0,
        "f1_score": latest_version.validation_f1 if latest_version else 0,
        "total_training_samples": training_samples,
        "task_executor": "OpenAI GPT-4",
        "learning_enabled": True,
        "notes": "Duke learns from OpenAI results to continuously improve"
    }

# ============================================================================
# ADMIN ENDPOINTS
# ============================================================================

@app.get("/api/v2/admin/metrics")
async def get_system_metrics(
    current_user: User = Depends(get_current_user),
    db: orm.Session = Depends(get_db)
):
    """Get system metrics"""
    if current_user.user_type not in ["admin"]:
        raise HTTPException(status_code=403, detail="Only admins can access")
    
    total_tasks = db.query(Task).count()
    total_users = db.query(User).count()
    completed_tasks = db.query(Task).filter(Task.status == "completed").all()
    total_satoshis = sum(t.price_satoshis for t in completed_tasks)
    
    results = db.query(Result).filter(Result.success == True).all()
    avg_success = (len(results) / len(completed_tasks)) if completed_tasks else 0
    
    training_samples = db.query(TrainingData).count()
    
    latest_version = db.query(ModelVersion).filter(
        ModelVersion.is_production == True
    ).first()
    
    return SystemMetrics(
        total_tasks=total_tasks,
        total_users=total_users,
        total_agents=1,  # OpenAI (+ Duke learning)
        average_success_rate=avg_success,
        total_satoshis_transacted=total_satoshis,
        training_samples_collected=training_samples,
        latest_model_version=f"v{latest_version.version_number}" if latest_version else "v0",
        latest_model_accuracy=latest_version.validation_accuracy if latest_version else 0.0
    )

# ============================================================================
# HEALTH & STATUS
# ============================================================================

@app.get("/api/v2/health")
async def health_check():
    """Health check"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow(),
        "openai_configured": bool(Config.OPENAI_API_KEY),
        "task_executor": "openai-gpt4",
        "duke_learning_enabled": True
    }

@app.get("/api/v2/version")
async def get_version():
    """Get API version"""
    return {
        "version": "2.0.0",
        "name": "DukeNET API",
        "task_execution": "OpenAI GPT-4",
        "learning_model": "Duke Labelee (learns from all activity)"
    }

# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
